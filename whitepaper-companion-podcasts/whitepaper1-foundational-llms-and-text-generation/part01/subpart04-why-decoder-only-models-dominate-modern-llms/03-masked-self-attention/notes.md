# ðŸ§  **Why Do We Need Masked Self-Attention?**

Decoder-only models **generate text one token at a time**.

Example: generating the sentence

> â€œThe cat sat down.â€

The model generates:

1. â€œTheâ€
2. â€œThe catâ€
3. â€œThe cat satâ€
4. â€œThe cat sat downâ€
5. â€¦

At step 3, the model should **not** be allowed to look at â€œdownâ€
â€” because it hasnâ€™t generated it yet.

So we must **hide future words** from the model during training.

That hiding = **masking**.

---

# ðŸŽ­ **Masked Self-Attention = Hiding the future from the model**

Imagine this table showing which words can â€œlook atâ€ which:

| Position | Can See | Cannot See    |
| -------- | ------- | ------------- |
| Token 1  | itself  | tokens 2,3,4â€¦ |
| Token 2  | 1,2     | tokens 3,4â€¦   |
| Token 3  | 1,2,3   | tokens 4,5â€¦   |
| Token 4  | 1,2,3,4 | tokens 5,6â€¦   |

The model is **allowed** to see only the tokens *before* it.
Future tokens are **blocked** (masked).

---

# ðŸ”’ **What does masking look like inside the model?**

Inside self-attention, every pair of tokens forms an attention score:

For token *i* attending to token *j*:

* if j â‰¤ i â†’ allowed
* if j > i â†’ forbidden (masked)

Forbidden means:

> The score is replaced with **âˆ’âˆž** (or a very large negative number).

So after softmax, the â€œfuture tokenâ€ gets **zero attention**.

---

# ðŸ‘ï¸ **Intuitive Example**

Sentence:

> â€œThe tiger drank waterâ€

When generating â€œtigerâ€, the model can see:

* â€œTheâ€

But it cannot see:

* â€œdrankâ€
* â€œwaterâ€

Because those happen in the future.

If it could see â€œdrank waterâ€, it would be cheating.
Masked attention prevents cheating.

---

# ðŸ§© **Why masking matters:**

### âœ”ï¸ Prevents cheating during training

The model must *learn* to predict next tokens from **prior context only**.

### âœ”ï¸ Supports auto-regressive generation

Masked self-attention mirrors actual generation behavior.

### âœ”ï¸ Enables chain-of-thought reasoning

Each new token builds on all previous ones.

---

# ðŸ”¥ **Masked vs Unmasked Self-Attention**

| Architecture | Attention Type | Meaning                            |
| ------------ | -------------- | ---------------------------------- |
| **Encoder**  | Unmasked       | Every token sees every other token |
| **Decoder**  | Masked         | Each token sees only past tokens   |

---

# ðŸ§  **Masked Self-Attention in ONE sentence**

> **Masked self-attention hides future tokens, ensuring the model only uses past information while generating text.**
